{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5dd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio \n",
    "from rasterio.plot import reshape_as_image, reshape_as_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27748dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1897800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(\"/Users/danylo_kunyk/Desktop/africa/data/ai-challenge/test/2d35f1/2d35f1.tif\") as src:\n",
    "    meta = src.meta\n",
    "    data = src.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19395e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d48a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.imshow(reshape_as_image(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f989e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9baf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "dataset_dir = Path(\"/Users/danylo_kunyk/Desktop/africa/data/ai-challenge/\")\n",
    "\n",
    "\n",
    "\n",
    "download_base_path = \"https://data.source.coop/open-cities/ai-challenge/{dataset_rel_path}\"\n",
    "\n",
    "\n",
    "for split_dir in dataset_dir.rglob(\"*train_tier_*\"):\n",
    "    if not split_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    cities = list(split_dir.glob(\"*\"))\n",
    "    for city_dir in tqdm(cities):\n",
    "        if not city_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        #labels_dir\n",
    "        print(\"labels_dirs\")\n",
    "        labels_dirs = list(city_dir.glob(\"*-labels\"))\n",
    "        for labels_dir in labels_dirs:\n",
    "            labels_path =  (labels_dir / f\"{labels_dir.name}.geojson\")\n",
    "            if not labels_path.exists():\n",
    "                \n",
    "                download_path = download_base_path.format(dataset_rel_path=labels_path.relative_to(dataset_dir))\n",
    "                os.system(f\"wget {str(download_path)} -O {str(labels_path)}\")\n",
    "            \n",
    "            if not labels_path.with_suffix(\".json\").exists():\n",
    "                download_path = download_base_path.format(dataset_rel_path=labels_path.with_suffix(\".json\").relative_to(dataset_dir))\n",
    "                os.system(f\"wget {str(download_path)} -O {str(labels_path.with_suffix(\".json\"))}\")\n",
    "                \n",
    "                \n",
    "                \n",
    "        #data dir\n",
    "        print(\"data_dirs\")\n",
    "        for data_dir in city_dir.glob(\"*\"):\n",
    "            if data_dir in labels_dirs or not data_dir.is_dir():\n",
    "                # print(f\"skip {data_dir}\")\n",
    "                continue \n",
    "                \n",
    "            \n",
    "            data_path = data_dir / f\"{data_dir.name}.tif\"\n",
    "            if not data_path.exists():\n",
    "                download_path = download_base_path.format(dataset_rel_path=data_path.relative_to(dataset_dir))\n",
    "                print(f\"wget {str(download_path)} -O {str(data_path)}\")\n",
    "                os.system(f\"wget {str(download_path)} -O {str(data_path)}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b245f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c1a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "dataset_dir = Path(\"/Users/danylo_kunyk/Desktop/africa/data/ai-challenge/\")\n",
    "\n",
    "\n",
    "\n",
    "download_base_path = \"https://data.source.coop/open-cities/ai-challenge/{dataset_rel_path}\"\n",
    "\n",
    "\n",
    "for split_dir in dataset_dir.rglob(\"*train_tier_*\"):\n",
    "    if not split_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    cities = list(split_dir.glob(\"*\"))\n",
    "    for city_dir in tqdm(cities):\n",
    "        if not city_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        #labels_dir\n",
    "        print(\"labels_dirs\")\n",
    "        labels_dirs = list(city_dir.glob(\"*-labels\"))\n",
    "        for labels_dir in labels_dirs:\n",
    "            labels_path =  (labels_dir / f\"{labels_dir.name}.geojson\")\n",
    "            if not labels_path.exists():\n",
    "                \n",
    "                download_path = download_base_path.format(dataset_rel_path=labels_path.relative_to(dataset_dir))\n",
    "                os.system(f\"wget {str(download_path)} -O {str(labels_path)}\")\n",
    "            \n",
    "            if not labels_path.with_suffix(\".json\").exists():\n",
    "                download_path = download_base_path.format(dataset_rel_path=labels_path.with_suffix(\".json\").relative_to(dataset_dir))\n",
    "                os.system(f\"wget {str(download_path)} -O {str(labels_path.with_suffix(\".json\"))}\")\n",
    "                \n",
    "                \n",
    "                \n",
    "        # #data dir\n",
    "        # print(\"data_dirs\")\n",
    "        # for data_dir in city_dir.glob(\"*\"):\n",
    "        #     if data_dir in labels_dirs or not data_dir.is_dir():\n",
    "        #         # print(f\"skip {data_dir}\")\n",
    "        #         continue \n",
    "                \n",
    "            \n",
    "        #     data_path = data_dir / f\"{data_dir.name}.tif\"\n",
    "        #     if not data_path.exists():\n",
    "        #         download_path = download_base_path.format(dataset_rel_path=data_path.relative_to(dataset_dir))\n",
    "        #         print(f\"wget {str(download_path)} -O {str(data_path)}\")\n",
    "        #         os.system(f\"wget {str(download_path)} -O {str(data_path)}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "dataset_dir = Path(\"/Users/danylo_kunyk/Desktop/africa/data/ai-challenge/\")\n",
    "\n",
    "download_base_path = \"https://data.source.coop/open-cities/ai-challenge/{dataset_rel_path}\"\n",
    "\n",
    "\n",
    "for split_dir in dataset_dir.rglob(\"*train_tier_*\"):\n",
    "    if not split_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    cities = list(split_dir.glob(\"*\"))\n",
    "    for city_dir in tqdm(cities):\n",
    "        if not city_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        #labels_dir\n",
    "        print(\"labels_dirs\")\n",
    "        labels_dirs = list(city_dir.glob(\"*-labels\"))\n",
    "        for labels_dir in labels_dirs:\n",
    "            \n",
    "            json_path =  labels_dir / f\"{labels_dir.name}.json\" \n",
    "            geojson_path = labels_dir / f\"{labels_dir.name.replace('-labels', '')}.geojson\"\n",
    "            \n",
    "            rel_path_json = json_path.relative_to(dataset_dir) \n",
    "            rel_path_geojson = geojson_path.relative_to(dataset_dir) \n",
    "            download_path_json = download_base_path.format(dataset_rel_path=rel_path_json)\n",
    "            download_path_geojson = download_base_path.format(dataset_rel_path=rel_path_geojson)\n",
    "            print(download_path_json, download_path_geojson)\n",
    "            os.system(f\"wget {str(download_path_json)} -O {str(json_path)}\")\n",
    "            os.system(f\"wget {str(download_path_geojson)} -O {str(geojson_path)}\")\n",
    "\n",
    "\n",
    "            \n",
    "                \n",
    "                \n",
    "        # #data dir\n",
    "        # print(\"data_dirs\")\n",
    "        # for data_dir in city_dir.glob(\"*\"):\n",
    "        #     if data_dir in labels_dirs or not data_dir.is_dir():\n",
    "        #         # print(f\"skip {data_dir}\")\n",
    "        #         continue \n",
    "                \n",
    "            \n",
    "        #     data_path = data_dir / f\"{data_dir.name}.tif\"\n",
    "        #     if not data_path.exists():\n",
    "        #         download_path = download_base_path.format(dataset_rel_path=data_path.relative_to(dataset_dir))\n",
    "        #         print(f\"wget {str(download_path)} -O {str(data_path)}\")\n",
    "        #         os.system(f\"wget {str(download_path)} -O {str(data_path)}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f977fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00739a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (6.9 kB)\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from torchvision) (12.0.0)\n",
      "Collecting PyYAML<8.0,>5.4 (from lightning)\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: packaging<27.0,>=20.0 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from lightning) (25.0)\n",
      "Collecting torchmetrics<3.0,>0.7.0 (from lightning)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from lightning) (4.67.1)\n",
      "Collecting pytorch-lightning (from lightning)\n",
      "  Downloading pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting scipy>=1.10.0 (from albumentations)\n",
      "  Downloading scipy-1.16.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from albumentations) (2.12.4)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Downloading stringzilla-4.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (110 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Downloading simsimd-6.5.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (70 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<2027.0,>=2022.5.0->lightning)\n",
      "  Downloading aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/danylo_kunyk/Desktop/africa/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning)\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning)\n",
      "  Downloading multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning)\n",
      "  Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning)\n",
      "  Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.8/74.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio lightning albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574e3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
